---
title: "Power analysis"
author: "PSA 008"
date: "R&R v. 4"

bibliography: references.bib  

output:
  html_document:
    number_sections: true
    toc: true
    code_folding: show
---

# README {-}

This document describes the power analysis for PSA 008 Minimal Groups. It is split into three parts. 

Section 1 details the general approach, how various parameters were derived, and how the dataset was simulated.

Section 2 shows the code used for the power analysis output reported in the manuscript, as well as reporting the output of the power analysis. Specifically, the power analysis using the mixed-effects modelling approach. The code iterates over different combinations of number of participants, number of countries, effect sizes, and random intercepts. By default, the number of simulations is set to 10 so that this document can be compiled. To reproduce the power analysis results reported in the manuscript, this should be changed to 1,000. This is time and resource intensive, with each simulation taking approximately 5 hours to complete when using 1,000 simulations. We used the University of Oxford Advanced Research Computing (ARC) facility (http://dx.doi.org/10.5281/zenodo.22558). This is why users should troubleshoot using a smaller number of simulations.

Section 3 provides the power analysis for the meta-analytic approach to RQ1.

# Packages {-}

```{r, package-information, message = FALSE}
## R package information

## load-packages
## list of packages required
packages <- c(
  "tidyverse", # data wrangling
  "lme4", # random effects models
  "lmerTest", # random effects models
  "simr", # simulating data
  "pwr", # power test
  "furrr", # iterate over multiple inputs
  "progressr", # display progress bar
  "patchwork" # combine plots
)
## create list of packages that have not been installed
new_packages <-
    packages[!(packages %in% installed.packages()[,"Package"])]
## install packages that have not been installed
if (length(new_packages)) 
    install.packages(new_packages, dependencies = TRUE)
## load all packages
sapply(packages, library, character.only = TRUE)

source("./custom-functions.R") # load custom functions

set.seed(1970) # to reproduce analysis
```

# General information {#sec:parameters}

As outlined in the analysis plan in the main text, we have three main research questions (RQs). RQ1 assesses whether intergroup bias with minimal groups (i.e. the minimal group effect) holds across the societies we will sample. RQ2 assesses whether the minimal group effect varies as a function of key moderators derived from the literature. RQ3 looks at the relationship between the minimal group effect and bias with real-world groups. Full details are in the manuscript.

For all research questions, the aim of the power analysis is to calculate the number of participants per country, given three parameters: significance level, power, and effect size/beta.

* We set the significance level to $alpha = .05/3 = .017$. This is because there are three outcomes tested within each research question. In RQ1 the outcome is an attitude or allocation; in RQ2 and RQ3 the outcome is a measure of bias (the difference between the in-group and the out-group in either first-party allocation, third-party allocation, or attitudes, for either minimal or real-world groups).

* Given our frequentist analysis plans, the a priori power is set to $beta = 0.95$ or higher.

* For RQ1, the outcome is the decision in the game or the evaluative attitude, and we are interested in powering for the effect of minimal group (a predictor coding for in-group vs out-group) on this decision. We looked to the literature for an indication of effect size for the minimal group effect. We derived three values. The smallest value of $0.19$ is based on @Balliet-et-al_2014, a meta-analysis of intergroup discrimination in behavioural economic games. This corresponds with the average effect size in games lacking mutual interdependence, like the allocation games we plan to run. It is also approximately half the overall effect size of games involving experimentally created (i.e. minimal) groups reported in @Balliet-et-al_2014 ($d = 0.35; 0.27-0.42)$, as well as the overall effect size of $d = 0.37 (0.28-0.45; n = 150)$ in games involving "artificial" (i.e. minimal) groups reported in @Lane_2016. The middle value of $0.27$ corresponds to the lower confidence interval for the overall effect size reported in @Balliet-et-al_2014, and the largest value of $0.35$ corresponds to the overall effect size.

* For RQ2, the outcome is bias (difference between in-group and out-group) in the decision, and we are interested in powering for the effect of one of our moderators (e.g. self-esteem, trust) group (in-group vs out-group) on this decision. We looked to the literature, and used two values. One value was $0.11$, which was derived from our pilot 02 data, specifically the correlation between self-esteem and minimal group effect. The other value was $0.42$, which was estimated from the effect of State Trust on the rate of cooperation using the meta-regression tool on the Cooperation Databank (https://app.cooperationdatabank.org/). The meta-regression (restricted ML estimator) reported a beta of 0.419 when conducted on 2022-11-22, which was composed of 11 effects and a total of 2,036 participants.

* For RQ3, the outcome is bias with real-world (i.e. national and family) groups. We derived an effect size based on literature reporting studies with national groups, as this is more common than with family groups. Effects sizes relevant to national groups in economic tasks are a meta-analysis and a recent cross-cultural study. @Lane_2016 reports an overall effect size of "national" groups $d = 0.16 (0.04â€“0.29; n = 52)$, and @Romano-et-al_2021 conducted a study across 42 nations finding $d = 0.22 (0.19-0.25)$ (this compares in-group with out-group plus strangers; from supplementary figures, it appears that the difference between in-group and out-group is less than in-group and stranger, so the overall effect size for in-group vs. out-group is likely less than $0.22$). We are not aware of an overall effect size of family from a meta-analysis or large scale study to report an effect size. The standardised coefficient estimated from @Romano-et-al_2021 was 0.10. Thus, we set the relevant coefficient to the smaller value of 0.10, which is the same used for RQ1 and RQ2. Most importantly, the primary effect of interesting in RQ3 is the effect of MGE on real-world bias. Because we are unaware of past research upon which to base an estimate of this effect we appraoched it via a sensitivty analysis, setting an expected value based on our Pilot 2 data, from which we observed an effect of .13. We thus estimate values from .05 to .20 in steps of .05.

For all RQs, we used the "simr" package [@Green-McLeod_2016], which allows for the a simplified version of the planned statistical model to be specified and the power calculated for a varying number of participants per country, number of countries, and country intercept variances. For all these calculations, we used simulated data. The simulated data used the results from the second pilot to specify the outcome per country for RQ1 and RQ2 (i.e. minimal group bias) and for RQ3 (i.e. real-world bias). In addition, for RQ2 we generated one of the measures (self-esteem), for which we have a good cross-country estimate using a similar scale as reported in @Robins-et-al_2001.

# Complete power analysis

The first thing to set is the number of simulations. This is set to 10 for troubleshooting, but in order to reproduce the results of the power analysis used in the manuscript the number of simulations should be set to 1,000. This can be acheived by placing ## in front of the number of simulations you do not want.

```{r, n-simulations}
n_sim <- 10 # to troubleshoot
## n_sim <- 1000 # actual run
```

We conduct a power analysis for each research question (RQ), using a version of the pre-specified mixed-models we will conduct as part of the planned analyses. The specification was trimmed. Only the random intercept for country was included. No random slopes were included because of in the absence of reliable estimates from prior literature and computational issues. 

For each fixed effect we specify the beta coefficients, for each random effect the variance, and finally the error variance (\ie sigma). Coefficients for the effects of interest (group for RQ1, a single moderator for RQ2, the relationship between the minimal group effect and real group bias in RQ3) were based on expectations from the literature or from our Pilot 2 data. The variance was set to multiple values. The error variance is set to 1 in all models.

We display the code that generates the output. Warning, this code below is computational intensive. It is advised that users run the code with a smaller number of iterations, or a subset of parameters. We print the output in a table for easy viewing. These pull in the `.csv` files saved in the repository, which contain the output from the the full run of 1,000 simulations.

## Codebook

Please refer to the following codebook for the headers in the power analysis output.

```{r, rq1-1000-codebook, echo = FALSE, message = FALSE, results = "asis"}
read_csv("pwr-rqs-codebook.csv") %>%
  knitr::kable(., caption = "Codebook for power analysis output tables")
```

## Research question 1

The output for RQ1 is generated by the following iterative code. We initially examined power for participant samples of 100 to 400 in steps of 50 but given that power asymptoted at lower sample sizes we here present results for samples of 100 to 250 in steps of 50.

```{r, rq1-iter, eval = FALSE}
## function to simulate data and run power analysis
simulation_swarm_rq1 <- function(n_ids, n_countries, beta, random_intercept) {
      
    ## create subject ids
    ids <- (1:n_ids) # start with n subjects per country
    
    ## create list of country names
    country_names <-
        letters_beyond_single_digits(n_countries) %>%
        tibble() %>%
        pull()
    
    ## create dataframe
    fake_data <-
        tibble(expand.grid(id = ids, country = country_names)) %>%
        mutate(id = c(1:nrow(.)))
        
    ## number of participants
    n_total <- nrow(fake_data)
    
    ## RQ1 variables
    
    ## create one of the minimal group dependent measures, based on the
    ## average attitude towards in-group and towards out-group
    ## mean values are taken from pilot 02, sd set to 1
    
    ## add outcomes for RQ1
    fake_data <-
        fake_data %>%
        mutate(min_in = round(
                   rtruncnorm(n_total, mean = 6.74, sd = 1, min = 0, max = 20), 0),
               min_out = round(
                   rtruncnorm(n_total, mean = 5.83, sd = 1, min = 0, max = 20), 0)
               ) %>%
        mutate(min_bias = min_in - min_out)

    ## extract dataframe that has "n" participants across "c" countries
    ## make long-form dataframe
    df <-
        fake_data %>%
        pivot_longer(cols = c("min_in", "min_out"),
                     names_to = "group",
                     values_to = "decision") %>%
        mutate(group = if_else(group == "min_in", "in", "out")) %>%
        select(id, country, group, decision)
    
    ## extract number of countries and participants per country
    ## to include in summary output
    n_country <- pull(count(unique(select(df, country))))
    n_id <- pull(count(unique(select(df, id))))/n_country

    ## sigma in models
    residual_sd <- 1
    
    ## fixed intercepts 
    fixed <-c(
        0 # intercept
      , beta # beta for group, based on standardized minimal group effect
    )
    
    ## random intercepts
    random <- list(
        random_intercept # for country
      , .40 # for id, estimated from pilot 02 data (= 0.389)
    )
    
    ## construct model
    ## in final analyses, we will include (group | country):
    ## decision ~ group + (1 | id) + (group | country)
    ## but we use a simplier specification for the power analysis
    model_rq1 <-
        makeLmer(
            decision ~ group + (1 | country) + (1 | id),
            fixef = fixed, 
            VarCorr = random, 
            sigma = residual_sd, 
            data = df                 
        )

    ## check overall power
    sim_rq1 <- 
        powerSim(
            model_rq1,
            test = fixed("group"),
            nsim = n_sim,
            alpha = 0.05/3
        )

    ## assign powersim to object for later use
    summary_sim_rq1 <-

    summary(sim_rq1) %>%
    mutate(n_ids = n_id,
           n_countries = n_country,
           beta_group = beta,
           random_country = random_intercept,
           class = "rq1"
           )
    
}

## create tibble with all combinations of parameters
parameter_space_rq1 <-

    crossing(
        n_ids = c(100, 150, 200, 250), # number of participants per country
        n_countries = c(20, 30, 40, 50, 60), # number of countries
        beta = c(0.19, 0.27, 0.35), # beta for "group" predictor
        random_intercept = c(0.3, 0.9, 1.5) # for "country" random intercept
    )

## run power analysis across all parameters
pwr_rq1 <-
     
    future_pmap_dfr(parameter_space_rq1,
                    simulation_swarm_rq1,
                    .options = furrr_options(seed = TRUE),
                    .progress = TRUE
                    )

## print output
print(pwr_rq1)

## save in one csv for later use
pwr_rq1 %>%
    write.csv(file = paste0("./pwr-rq1.csv"))
```

Here is the output for RQ1. In sum, we are sufficiently powered across all parameters we have tested.

```{r, rq1-1000-results, echo = FALSE, message = FALSE, results = "asis"}
## create plot
plot_power_rq1 <- 
  
  read_csv("pwr-rq1.csv") %>%
  mutate(n_countries = as.factor(n_countries)) %>%
  ggplot() +
  aes(x = n_ids, y = mean, group = n_countries, colour = n_countries) +
  geom_point(size = 3) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_hline(yintercept = 0.95, linetype = 2) +
  ylim(0.70, 1.00) +
  facet_wrap(beta_group ~ random_country,
             scales = "free_x",
             labeller = labeller(random_country = as_labeller(
                                       c("0.3" = "random intercept = 0.3",
                                         "0.9" = "random intercept = 0.9",
                                         "1.5" = "random intercept = 1.5"
                                         )),
                                   beta_group = as_labeller(
                                      c("0.19" = "effect of group = 0.19",
                                         "0.27" = "effect of group = 0.27",
                                         "0.35" = "effect of group = 0.35"
                                    )))
               ) +
    scale_colour_brewer(palette = "Dark2",
                        name = "number of\ncountries",
                        na.translate = FALSE) +
    labs(x = "sample size (total n)",
         y = "power (beta)") +
    guides(colour = guide_legend(reverse = TRUE)) +
    labs(title = "Power analysis RQ1") +
    theme_bw(
      ## base_size = 30 ## for legibility of printed plot, comment out size
    ) +
    theme(panel.spacing = unit(0.5, "lines"),
          strip.text.x = element_text(margin = margin(unit(1, "lines"))),
          strip.background = element_blank(),
          strip.placement = "outside")

## print plot
plot_power_rq1

## save plot
## plot_power_rq1 %>%
##     ggsave(filename = paste(Sys.Date(), "pwr-rq1.png", sep = "_"),  
##           bg = "transparent")
```

## Research question 2

The output for RQ2 is generated by the following iterative code.

```{r, rq2-iter, eval = FALSE}
## simulate data
simulation_swarm_rq2 <- function(n_ids, n_countries, beta, random_intercept) {
      
    ## create subject ids
    ids <- (1:n_ids) # start with n subjects per country
    
    ## create list of country names
    country_names <-
        letters_beyond_single_digits(n_countries) %>%
        tibble() %>%
        pull()
    
    ## create dataframe
    fake_data <-
        tibble(expand.grid(id = ids, country = country_names)) %>%
        mutate(id = c(1:nrow(.)))
        
    ## number of participants
    n_total <- nrow(fake_data)

    ## RQ1 variables
    
    ## create one of the minimal group dependent measures, based on the
    ## average attitude towards in-group and towards out-group
    ## mean values are taken from pilot 02, sd set to 1
    
    ## add outcomes for RQ1
    fake_data <-
        fake_data %>%
        mutate(min_in = round(
                   rtruncnorm(n_total, mean = 6.74, sd = 1, min = 0, max = 20), 0),
               min_out = round(
                   rtruncnorm(n_total, mean = 5.83, sd = 1, min = 0, max = 20), 0)
               ) %>%
        mutate(min_bias = min_in - min_out)

    ## RQ2 variables    
    ## generate one of the measures, we use self-esteem as we have a good
    ## cross-country estimate using a similar scale
    
    ## generate self-esteem
    self_esteem_score <- 
        
        rnorm(n_ids
            , mean = 3.5, sd = 1 # adapted from Robins-et-al_2001
              ) 

    ## add to artificial data frame
    ## each repeated n times for each country
    fake_data <-
        
        fake_data %>%
        mutate(self_esteem = rep(self_esteem_score, n_countries)
               )
    
    ## extract dataframe that has "n" participants across "c" countries
    df <-
        
        fake_data

    ## extract number of countries and participants per country
    ## to include in summary output
    n_country <- pull(count(unique(select(df, country))))
    n_id <- pull(count(unique(select(df, id))))/n_country
    
    ## sigma in models
    residual_sd <- 1

    ## fixed intercepts
    fixed <- c(
        0.19 # intercept, based on smallest effect size 
      , beta # beta for self-esteem, which varies
    )
    ## based on beta 0.419 from https://app.cooperationdatabank.org/
    
    ## random intercepts
    random <- list(
        random_intercept # for country
    )
    
    ## construct model
    model_rq2 <- 
        
        makeLmer(
            min_bias ~ self_esteem + (1 | country),
            fixef = fixed, 
            VarCorr = random, 
            sigma = residual_sd, 
            data = df                 
        )
    
    ## check power
    sim_rq2 <- 
        
        powerSim(
            model_rq2,
            test = fixed("self_esteem"),
            nsim = n_sim,
            alpha = 0.05/3
        )
    
    sim_rq2
    
    ## assign powersim to object for later use
    summary_sim_rq2 <-
        
        summary(sim_rq2) %>%
        mutate(n_ids = n_id,
               n_countries = n_country,
               beta_predictor = beta,
               random_country = random_intercept,
               class = "rq2"
               )
    
    summary_sim_rq2
    
}

## create tibble with all combinations of parameters
parameter_space_rq2 <-

    crossing(
        n_ids = c(100, 150, 200, 250), # number of participants per country
        n_countries = c(20, 30, 40, 50, 60), # number of countries
        beta = c(0.10, 0.25, 0.40), # beta for "self-esteem" predictor
        random_intercept = c(0.3, 0.9, 1.5) # for "country" random intercept
    )

## run power analysis across all parameters
pwr_rq2 <-
     
    future_pmap_dfr(parameter_space_rq2,
                    simulation_swarm_rq2,
                    .options = furrr_options(seed = TRUE),
                    .progress = TRUE
                    )

## print output
print(pwr_rq2)

## save in one csv for later use
pwr_rq2 %>%
    write.csv(file = paste0("./pwr-rq2.csv"))
```

Here is the output for RQ2. In sum, we are sufficiently powered across all parameters we have tested.

```{r, rq2-1000-results, echo = FALSE, message = FALSE, results = "asis"}
## create plot
plot_power_rq2 <- 
  
  read_csv("pwr-rq2.csv") %>%
  mutate(n_countries = as.factor(n_countries)) %>%
  ggplot() +
  aes(x = n_ids, y = mean, group = n_countries, colour = n_countries) +
  geom_point(size = 3) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_hline(yintercept = 0.95, linetype = 2) +
  ylim(0.70, 1.00) +
  facet_wrap(beta_predictor ~ random_country,
             scales = "free_x",
             labeller = labeller(random_country = as_labeller(
                                       c("0.3" = "random intercept = 0.3",
                                         "0.9" = "random intercept = 0.9",
                                         "1.5" = "random intercept = 1.5"
                                         )),
                                   beta_predictor = as_labeller(
                                      c("0.1" = "effect of predictor = 0.10",
                                         "0.25" = "effect of predictor = 0.25",
                                          "0.4" = "effect of predictor = 0.40"
                                    )))
               ) +
    scale_colour_brewer(palette = "Dark2",
                        name = "number of\ncountries",
                        na.translate = FALSE) +
    labs(x = "sample size (total n)",
         y = "power (beta)") +
    guides(colour = guide_legend(reverse = TRUE)) +
    labs(title = "Power analysis RQ2") +
    theme_bw(
      ## base_size = 30 ## for legibility of printed plot, comment out size
    ) +
    theme(panel.spacing = unit(0.5, "lines"),
          strip.text.x = element_text(margin = margin(unit(1, "lines"))),
          strip.background = element_blank(),
          strip.placement = "outside")

## print plot
plot_power_rq2

## save plot
## plot_power_rq2 %>%
##     ggsave(filename = paste(Sys.Date(), "pwr-rq2.png", sep = "_"),  
##           bg = "transparent")
```

## Research question 3

Finally, the output for RQ3 is generated by the following iterative code.

```{r, rq3-iter, eval = FALSE}

## simulate data
simulation_swarm_rq3 <- function(n_ids, n_countries, beta, random_country) {
    
    ## and that vary in number of participants per country
       
        ## create subject ids
        ids <- (1:n_ids) # start with n subjects per country
        
        ## create list of country names
        country_names <-
            
            letters_beyond_single_digits(n_countries) %>%
            tibble() %>%
            pull()
        
        ## create dataframe
        fake_data <-
            
            expand.grid(id = ids, country = country_names) %>%
            tibble() %>%
            mutate(id = c(1:nrow(.)))
        
        ## number of participants
        n_total <- nrow(fake_data)
        
        ## RQ1 variables
        
        ## create one of the minimal group dependent measures, based on the
        ## average attitude towards in-group and towards out-group
        
        ## mean and sd values are taken from pilot 02
        
        ## add outcomes for RQ1
        fake_data <-
            
            fake_data %>%
            mutate(min_in = 
                       round(
                           rtruncnorm(n_total, 
                                      mean = 6.74, sd = 1, min = 0, max = 20), 
                           0),
                   min_out = 
                       round(
                           rtruncnorm(n_total, 
                                      mean = 5.83, sd = 1, min = 0, max = 20), 
                           0)
                   ) %>%
            mutate(min_bias = min_in - min_out)

        ## RQ3 variables

        ## mean and sd values are taken from pilot 02
        
        ## add real-world measures
        fake_data <-
            
            fake_data %>%
            ## nation
            mutate(
                nat_in = 
                    round(
                        rtruncnorm(n_total, 
                                   mean = 6.29, sd = 1, min = 0, max = 20), 
                        0),
                nat_out = 
                    round(
                        rtruncnorm(n_total, 
                                   mean = 6.26, sd = 1, min = 0, max = 20), 
                        0)) %>%
            mutate(nat_bias = nat_in - nat_out) %>%
            ## family        
            mutate(
                fam_in = 
                    round(
                        rtruncnorm(n_total, 
                                   mean = 3, sd = 1, min = 0, max = 10), 
                        0),
                fam_out = 
                    round(
                        rtruncnorm(n_total, 
                                   mean = 1, sd = 1, min = 0, max = 10), 
                        0)) %>%
            mutate(fam_bias = fam_in - fam_out)
    
        ## dataframe
        df <-
            
            fake_data %>%
            pivot_longer(cols = c("nat_bias", "fam_bias"),
                         names_to = "group_type", values_to = "real_bias") %>%
            rename(MGE = min_bias) %>%
            separate(group_type, into = c("group_type", "bias")) %>%
            select(id, country, MGE, group_type, real_bias)
        
    ## extract number of countries and participants per country
    ## required for producing output
    n_country <- pull(count(unique(select(df, country))))
    n_id <- pull(count(unique(select(df, id))))/n_country
  
    ## sigma in models
    residual_sd <- 1

    ## fixed intercept 
    fixed <- c(
        0.1 # intercept from Romano
      , beta # beta for MGE
      , 0.1 # beta for group_type
      , 0.1 # beta for interaction between MGE and group_type
    )
    
    ## random intercepts
    random <- list(
        random_country # for country
      , .40 # for id, estimated from pilot 02 data (= 0.389)
    )
    
    ## construct model
    ## in final analyses, we will include random slopes:
    ## decision ~ group_type + (1 | id) + (MGE + group_type | country)
    ## but we use a simpler specification for the power analysis
    model_rq3 <- 
        
        makeLmer(
            real_bias ~ MGE * group_type + (1 | country) + (1 | id), 
            fixef = fixed, 
            VarCorr = random, 
            sigma = residual_sd, 
            data = df                 
        )
    
    ## check power
    sim_rq3 <- 
      
      powerSim(
        model_rq3,
        test = fixed("MGE", method = "z"),
        nsim = n_sim,
        alpha = 0.05/3
      )
    
    sim_rq3

     ## assign powersim to object for later use
    summary_sim_rq3 <-
      
      summary(sim_rq3) %>%
      mutate(n_ids = n_id,
             n_countries = n_country,
             beta_MGE = beta,
             random = random_country,
             class = "rq3"
      )

    summary_sim_rq3
    
}

## create tibble with all combinations of parameters
parameter_space_rq3 <-

    crossing(
        n_ids = c(100, 150, 200, 250), # number of participants per country
        n_countries = c(20, 30, 40, 50, 60), # number of countries
        beta = c(0.05, 0.10, 0.15, 0.20), # beta for "MGE" 
        random_country = c(0.3, 0.9, 1.5) # for "country" random intercept
    )

## run power analysis across all parameters
pwr_rq3 <-
     
    future_pmap_dfr(parameter_space_rq3,
                    simulation_swarm_rq3,
                    .options = furrr_options(seed = TRUE),
                    .progress = TRUE
                    )

## print output
print(pwr_rq3)

## save in one csv for later use
pwr_rq3 %>%
    write.csv(file = paste0("./pwr-rq3.csv"))
```

Here is the output for RQ3. In sum, we are sufficiently powered across all parameters we have tested.

```{r, rq3-1000-results, echo = FALSE, message = FALSE,  results = "asis"}
## create plot
plot_power_rq3 <- 
  read_csv("pwr-rq3.csv") %>%
  mutate(n_countries = as.factor(n_countries)) %>%
  ggplot() +
  aes(x = n_ids, y = mean, group = n_countries, colour = n_countries) +
  geom_point(size = 3) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_hline(yintercept = 0.95, linetype = 2) +
  ylim(0.3, 1.00) +
  # scale_y_continuous(expand=expansion(multc(0.8,0.8))) +
  facet_wrap(beta_MGE ~ random_country,
             scales = "free",
             labeller = labeller(random_country = as_labeller(
                                       c("0.3" = "random intercept = 0.3",
                                         "0.9" = "random intercept = 0.9",
                                         "1.5" = "random intercept = 1.5"
                                         )),
                                   beta_MGE = as_labeller(
                                      c("0.05" = "effect of MGE = 0.05",
                                        "0.1" = "effect of MGE = 0.10",
                                         "0.15" = "effect of MGE = 0.15",
                                          "0.2" = "effect of MGE = 0.20"
                                    )))
               ) +
    scale_colour_brewer(palette = "Dark2",
                        name = "number of\ncountries",
                        na.translate = FALSE) +
    # scale_y_continuous(limits = c(ylimlow, 1.00)) +
    labs(x = "sample size (total n)",
         y = "power (beta)") +
    guides(colour = guide_legend(reverse = TRUE)) +
    labs(title = "Power analysis RQ3") +
    theme_bw(
      ## base_size = 30 ## for legibility of printed plot, comment out size
    ) +
    theme(panel.spacing = unit(0.5, "lines"),
          strip.text.x = element_text(margin = margin(unit(1, "lines"))),
          strip.background = element_blank(),
          strip.placement = "outside")
## print plot
plot_power_rq3

## save plot
## plot_power_rq3 %>%
##     ggsave(filename = paste(Sys.Date(), "pwr-rq3.png", sep = "_"),  
##           bg = "transparent")
```

# Meta-analytical approach for Research question 1

Meta-analytical approach based on "meta_analysis_power.R" script from @Quintana-Tiebel_2018 and @Valentine-et-al_2010.

```{r, rq1-meta-analysis}
## overall effect size
effect_size <- 0.19

## number of countries
## lower limit: 20 is a reasonable minimal number based on previous PSA projects
## upper limit: 60, as 59 countries expressed an interest at first submission
range_countries <- c(seq(20, 60, 10))

## number of participants per in-group/out-group decision
range_group <- c(seq(25, 250, 25))

## calculate critical z
c_z <- qnorm(p = (0.05/3)/2, # adjusted alpha, halved for two-tailed
             lower.tail = FALSE)

## create tibbles with estimated power

## across range of heterogeneity = tau squared
for (heterogeneity in c(.33, 1, 3)) {
    
    ## across range of countries
    for (n_k in range_countries) {
        
        ## across range of number of participants per in-group/out-group decision
        for (n_per_group in range_group) {
            
            eq1 <- 
                ((n_per_group + n_per_group)/((n_per_group) * (n_per_group))) + 
                ((effect_size^2)/(2*(n_per_group + n_per_group)))
            
            eq2 <- heterogeneity*(eq1)
        
            eq3 <- eq2 + eq1
            
            eq4 <- eq3/n_k
            
            eq5 <- (effect_size/sqrt(eq4))
        
            power <- (1 - pnorm(c_z - eq5)) # two-tailed
            
            power

            ## create tibbles
            assign(
                paste0("tbl_", n_per_group, "_", n_k, "_", heterogeneity),
                tibble(n = n_per_group, k = n_k, pwr = power, hg = heterogeneity))
            
        }
    }
    
}

## gather all tibbles 
gather_tbls <- grep("tbl", names(.GlobalEnv), value=TRUE)
tbls_list <- do.call("list", mget(gather_tbls))

## create plot
plot_power <-

    bind_rows(tbls_list) %>%
    mutate(k = as.factor(k)) %>%
    ggplot() +
    aes(x = n, y = pwr, group = k, colour = k) +
    geom_point(size = 3) +
    geom_line(alpha = 0.5, size = 1.5) +
    geom_hline(yintercept = 0.95, linetype = 2) +
    facet_wrap(. ~ hg,
               labeller = labeller(hg = as_labeller(c("0.33" = "0.33 (low heterogeneity)",
                                                      "1" = "1.00 (mid heterogeneity)",
                                                      "3" = "3.00 (high heterogeneity)"
                                                      )))) +
    scale_colour_brewer(palette = "Dark2",
                        name = "number of\ncountries",
                        na.translate = FALSE) +
    labs(x = "sample size (number of individuals per country)",
         y = "power (beta)") +
    guides(colour = guide_legend(reverse = TRUE)) +
    theme_bw(
      ## base_size = 33 ## for legibility of printed plot, comment out size
      ) 

## visualise plot
plot_power

 ## save plot # comment out to save in folder 
 # plot_power %>%
 #     ggsave(filename = paste(Sys.Date(), "power-rq1.png", sep = "_"),  
 #            bg = "transparent")
```

# Session information {-}

Below is the session info related to the versions of R and R packages used in the running of the iterative code.

```{r, sessioninfo}
## print sessionInfo produced by ARC
cat(readLines("./sessionInfo.txt"), sep = '\n')
```

# References {-}

<div id="refs"></div>